{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Bobby Baylon\n",
    "- Kyra Brandt\n",
    "- Jayson Gutierrez\n",
    "- Nathaniel Mackler\n",
    "- Stephen Rabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract (UPDATED please check)\n",
    "Our group is composed of Cognitive Science majors working together in an introductory supervised machine learning course at the University of California, San Diego. The goal of this project is to create a system for categorizing NBA players' injuries based on performance data. A KNN technique for multi-class classification will be used to accomplish this using datasets that include information on each player's performance statistics and instances of player injury. To gather player performance information, web scraping will be done using the nba api and injury data from Kaggle, which has 27,106 observations and 5 variables. Due to the sheer volume of features in the dataset, we will use feature selection to measure player performance statistics using integer values that reflect different performance indicators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background (NOT YET UPDATED)\n",
    "\n",
    "\n",
    "A hot topic within the current NBA world revolves around the idea of load management. The concept of load management dictates if a player should play on game day and, if they do, how many minutes. One hypothetical example is that an NBA organization might sit their star player out for a game halfway through the season because that player has been used at high rates in recent games. That organization might analyze their star's workload, ask the player how their body is responding, and assess that it's time to give their star a rest to prevent any risk of injuries, minor or major. \n",
    "Practicing load management seems like an obvious protocol for an organization in order to preserve both the player and the organization’s future health and success. A study conducted through the 2012-2015 seasons in 17 NBA teams demonstrated that significant factors in player injuries were high game loads and player fatigue <a name=\"lewis\"></a>[<sup>[1]</sup>](#lewisnote). This study reinforces that there’s an interaction between game load and injury risk, thus it's reasonable for fans, organizations, and players to assess minutes and games played to determine if a player should sit to prevent injury. Another study conducted using data from the 2017-2019 seasons found that other risk factors for injury were player age and position <a name=\"cohan\"></a>[<sup>[2]</sup>](#cohannote). This study indicates that seasoned players are more prone to injury and that player build’s are considerable factors in injuries due to the size expectations of certain positions.\n",
    "On the surface, it seems obvious to people outside of the NBA world that you would want to prevent major injuries for the players, that could even be career ending, and that forcing any individual to play regardless of their physical status would be unethical and harmful. However, traditional NBA fans and retired players argue that current players, especially star players, shouldn’t sit due to fatigue or minor injuries as it robs fans of their full experience at an NBA game. When the late great Kobe Bryant was asked why he disapproves of modern NBA players sitting out due to fatigue, he replied perfectly, “Because you have a lot of people paying a lot of money to come see these athletes play, and they deserve to see that.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement (NOT YET UPDATED)\n",
    "\n",
    "The problem we’re attempting to solve is to classify NBA player injuries based on performance statistics such as usage rating, minutes played, and games played. One solution we’re leaning towards is implementing a KNN algorithm to classify the injuries with respect to the performance statistics. One reason we’re considering using a KNN implementation is that it is a strong algorithm for multi-class classification if we wanted to classify injury statuses in a hierarchy of non-injured, minor injury, or major injury. KNN can also handle categorical data such as player position, because some injuries are more common than others at certain positions we’re going to use a one-hot encoding to describe the position feature of players. One might caution against using KNN, as the datasets available to us describe a player across 20+ features, with some of those features being categorical. Thus for those features that are categorical, the dimensionality of our data might increase drastically. And because KNN suffers in higher dimensions due to expensive computations, we might need to do some sort of feature selection depending on our implementation. However, we’d be testing each datapoint at most thousands or tens of thousands of times in a year, across roughly 15 years, meaning that we wouldn’t require extensive amounts of time for testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data (NOT YET UPDATED)\n",
    "\n",
    "UPDATED FROM PROPOSAL!\n",
    "\n",
    "You should have obtained and cleaned (if necessary) data you will use for this project.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n",
    "\n",
    "## Copied from Proposal\n",
    "\n",
    "Currently, we are planning to use datasets containing individual player performance statistics and instances of player injury. While we do not have a concrete dataset for player performance statistics at present, we intend to use a public API for web scraping this information from the official NBA webpage (www.nba.com). \n",
    "\n",
    "Presently Known Data:\n",
    "\n",
    "Injury Data 2010-2020 (Kaggle):\n",
    "- Link: https://www.kaggle.com/datasets/ghopkins/nba-injuries-2010-2018?resource=download \n",
    "- Dataset size: 27,106 X 5 = 27,106 observations and 5 variables\n",
    "- A single observation consists of the name of the injured player, the team they played for while injured, notes detailing the injury, injury leave, and/or return from injury, and the date for which the player either left on injury leave or returned to play. \n",
    "- Some critical variables are the Required, Relinquished, and Notes variables. Required and Relinquished (based on whether or not a name is present) indicate whether a player is going on injury leave or returning to the field of play. Both of these variables are represented as string values and are categorical. The Notes variable contains more specific information on the injury (i.e. did not play or day-to-day [which is questionable to play]) and/or indicates the beginning or end of injury leave for a player. The Notes variable is represented as a string. \n",
    "- Cleaning and transforming are to be expected for this dataset. We may change the representation of Required and Relinquished to be integer values using one-hot encoding, seeing as these are categorical variables. Additionally, we may choose to consolidate observations pertaining to the leave and return of the same player for a given injury (i.e. adding an additional variable for date returned to remove redundant observations). Finally, we may also choose to calculate and add an additional variable of days injured to the dataset.\n",
    "\n",
    "Semi-Known Data:\n",
    "\n",
    "nba_api for web scraping (GitHub):\n",
    "- Link: https://github.com/swar/nba_api\n",
    "- Dataset size: Currently uncertain.\n",
    "- An observation will consist of different performance statistics for a given player (i.e. time played, points scored, number of rebounds, average free throws made, etc.)\n",
    "- Critical variables are currently unknown. We expect critical variables to highlight general player performance, which would suggest the importance of variables like average time played, average points scored in a game, and average shots made which would all be represented as integer values. The list of critical variables will change once the dataset has been constructed. \n",
    "- As the data is being acquired through web scraping, there will surely be some necessary cleaning of the data. In addition to the constructing of the dataset, the variables will need to be checked for data type and, if necessary, altered accordingly, and the data will likely need to be relabelled for easier comprehension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution (NOT YET UPDATED)\n",
    "\n",
    "K-nearest neighbors is an obvious solution for this use case. Realistically, one would need to predict the injury class of NBA players no more frequently than tens of thousands of times per year. Therefore, the high complexity of testing with KNN is a non-issue for this use case. The curse of dimensionality is also not a significant problem, as we have thousands of data points but only tens of features. However, a large vulnerability would be the risk of useless features affecting our KNN classifier. We don’t know for sure which features will matter. We may try to pick some features based on intuition - but there is no guarantee that features that have predictive power will be intuitively so. If we did choose to use KNN, then we could use built-in SKlearn methods - we would have to be careful to scale all our data by z-score, however. \n",
    "\n",
    "An alternative solution would be to use an SVM with an RBF kernel (or some other kernel that is appropriate for a data set where we have more observations than features; this is a tunable hyperparameter) to build a classifier. To do feature selection, we could use a grid search CV with C (the “hardness” of the margin) and different sets of features (first selected on intuition and research, as using all possible combinations would result in a ~2^20 by count(values of C) grid, which would result in easily overfitting to noise, be impossible to compute at our scale, and which we have insufficient data to cross validate. This would still be vulnerable to the intuition issue, but should be more resistant to overfitting to noise. Alternatively, I read online about recursive feature selection in SVMs - but I would want to talk about this with a TA before considering this technique, as it was not discussed in class. In any case, SVM is well-implemented in SKlearn, so we could use SKlearn for this process. \n",
    "\n",
    "In either case, a good benchmark model would be logistic regression using only age and minutes played. Intuitively, we expect that these two factors would be by far the most important in predicting whether a player will be injured, so if a complex model fails to do significantly better than this very simple model, we can safely dismiss it as not useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics (NOT YET UPDATED)\n",
    "\n",
    "The consequences of a false positive in this case is non-zero (potentially hurting a player’s mindset or causing them to reduce their performance), but small compared to the consequences of a false negative (an injury occurring that could have been prevented or whose probability could be reduced through better form/training/moderation). The obvious error metric for this case would be recall (TP/(TP+FN)), but this metric would give zero weight to false positives. The harm of false positives is not zero, just lower than that of false negatives. Therefore, I think the best metric would be an Fbeta metric. The value of beta is subjective. We will play around with a few values to determine the beta that “feels” right, but it should be over one to weight recall higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "- Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem \n",
    "- Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "- Showing the performance of a base model/hyper-parameter setting.  Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "- Learning curves or validation curves for a particular model\n",
    "- Tables/graphs showing the performance of different models/hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy (No need to update. We got full points on the proposal for this section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Communicate with one another using the team groupchat on Discord. Try to respond to messages within 24 hours if not sooner.*\n",
    "* *We will meet when necessary on Zoom. We will organize meeting times in Discord. Any anticipated absenses or schedule conflicts should be brought up with the team beforehand.*\n",
    "* *We will do our best to divide the work equally between members of the team.*\n",
    "* *Conflicts between team members should be brought up with the whole team, so that the other team members can mediate and help resolve the conflict.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/14 | 1 PM | Brainstorm topics/questions (all) | Introduce selves; Choose basic topic/area of interest for project; Begin looking for data sources|\n",
    "| 2/22  |  10 AM |  Find data/develop deeper understanding of topic (all)  | Divide work on project proposal among team members; Clarify research question | \n",
    "| **2/22** | **11:59 PM** | **PROJECT PROPOSAL DUE** |\n",
    "| 3/4  |  11:30 AM | Get and clean data from NBA API (Jayson), clean injury dataset and preliminary EDA (Nathaniel, Bobby) | Divide work for project checkpoint; Decide who will clean data and how models will be implemented and who will work on which ones | \n",
    "| 3/7  | 1 PM  | Implement(or be close to implementing) most if not all of the models | Edit, finalize, and submit checkpoint; Touch base on problems that arise; Discuss plans for next phase of project |\n",
    "| **3/8** | **11:59 PM** | **PROJECT CHECKPOINT DUE** |\n",
    "| 3/14  | 1 PM  | Do model selection; Calculate metrics | Review progress and tackle issues; Divide up work for final project notebook   |\n",
    "| 3/20  | 12 PM  | Draft final project notebook | Discuss/edit project code; Proofread final notebook; Complete project |\n",
    "| **3/22**  | **11:59 PM**  | **FINAL PROJECT DUE**  | Don't forget to fill out team evaluation survey! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lewisnote\"></a>1.[^](#lewis): Lewis, M. (2018). It’s a Hard-Knock Life: Game Load, Fatigue, and Injury Risk in the National Basketball Association. J Athl Train. https://meridian.allenpress.com/jat/article/53/5/503/112788/It-s-a-Hard-Knock-Life-Game-Load-Fatigue-and<br> \n",
    "<a name=\"cohannote\"></a>2.[^](#cohan): Cohan, A. Schuster, J. Fernandez, J. (2021). A deep learning approach to injury forecasting in NBA basketball. Journal of Sports Analytics. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
